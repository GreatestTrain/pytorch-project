{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "declared 4 variables\n"
     ]
    }
   ],
   "source": [
    "%run \"config.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "PYTHON_DIR = pathlib.Path(sys.executable).parent.parent.resolve()\n",
    "torch.ops.load_library(str(PYTHON_DIR.joinpath(\"lib\", \"libpt_ocl.so\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_channels) -> None:\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.conv1 = nn.Conv2d(3, self.num_channels, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(self.num_channels)\n",
    "        self.conv2 = nn.Conv2d(self.num_channels, self.num_channels * 2, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_channels*2)\n",
    "        self.conv3 = nn.Conv2d(self.num_channels * 2, self.num_channels * 4, 3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_channels*4)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.num_channels*4*8*8, self.num_channels*4)\n",
    "        self.fcbn1 = nn.BatchNorm1d(self.fc1.out_features)\n",
    "        self.fc2 = nn.Linear(self.num_channels*4, 6)\n",
    "\n",
    "    def forward(self, x): # (3, 64, 64)\n",
    "        x = self.conv1(x) # (n, 64, 64)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(F.max_pool2d(x, 2)) # (n, 32, 32)\n",
    "        x = self.conv2(x) # (2*n, 32, 32)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(F.max_pool2d(x, 2)) # (2*n, 16, 16)\n",
    "        x = self.conv3(x) # (2*n, 16, 16)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(F.max_pool2d(x, 2)) # (4*n, 8, 8)\n",
    "\n",
    "        # flatten\n",
    "        x = x.view(-1, self.num_channels*4*8*8)\n",
    "\n",
    "        # fc\n",
    "        x = self.fc1(x)\n",
    "        x = self.fcbn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p = 0.8, training=True)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # softmax\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGNSDataset():\n",
    "    def __init__(self, base_dir: str | pathlib.Path, split: str = \"train\", transform = None) -> None:\n",
    "        if isinstance(base_dir, str): base_dir = pathlib.Path(base_dir)\n",
    "        path = base_dir.joinpath(split)\n",
    "        files = path.iterdir()\n",
    "\n",
    "        self.filenames = list(filter(lambda x: str(x).endswith(\".jpg\"), files))\n",
    "        self.labels = [int(f.name[0]) for f in self.filenames]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.filenames[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = SIGNS_DIR.joinpath(\"64x64_SIGNS\")\n",
    "train_dataset = SIGNSDataset(DIR, \"train_signs\", transform=transforms.ToTensor())\n",
    "test_dataset = SIGNSDataset(DIR, \"test_signs\", transform=transforms.ToTensor())\n",
    "val_dataset = SIGNSDataset(DIR, \"val_signs\", transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "net = Net(32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningMetric():\n",
    "    def __init__(self) -> None:\n",
    "        self.S = 0\n",
    "        self.N = 0\n",
    "    \n",
    "    def update(self, val, size):\n",
    "        self.S += val\n",
    "        self.N += size\n",
    "\n",
    "    def __call__(self):\n",
    "        try:\n",
    "            return self.S / float(self.N)\n",
    "        except ZeroDivisionError as e:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 25\n",
      "----------\n",
      " Loss: 1.453837 - Accuracy 0.438657\n",
      " Loss: 1.332151 - Accuracy 0.482639\n",
      "Epoch 2 / 25\n",
      "----------\n",
      " Loss: 0.968095 - Accuracy 0.658565\n",
      " Loss: 0.882336 - Accuracy 0.688079\n",
      "Epoch 3 / 25\n",
      "----------\n",
      " Loss: 0.750735 - Accuracy 0.745370\n",
      " Loss: 0.674908 - Accuracy 0.786458\n",
      "Epoch 4 / 25\n",
      "----------\n",
      " Loss: 0.635300 - Accuracy 0.805556\n",
      " Loss: 0.598394 - Accuracy 0.817130\n",
      "Epoch 5 / 25\n",
      "----------\n",
      " Loss: 0.540780 - Accuracy 0.841435\n",
      " Loss: 0.512054 - Accuracy 0.855324\n",
      "Epoch 6 / 25\n",
      "----------\n",
      " Loss: 0.488755 - Accuracy 0.846065\n",
      " Loss: 0.441440 - Accuracy 0.869213\n",
      "Epoch 7 / 25\n",
      "----------\n",
      " Loss: 0.422175 - Accuracy 0.865741\n",
      " Loss: 0.439933 - Accuracy 0.859954\n",
      "Epoch 8 / 25\n",
      "----------\n",
      " Loss: 0.375720 - Accuracy 0.901620\n",
      " Loss: 0.353266 - Accuracy 0.901620\n",
      "Epoch 9 / 25\n",
      "----------\n",
      " Loss: 0.341621 - Accuracy 0.906250\n",
      " Loss: 0.319111 - Accuracy 0.914352\n",
      "Epoch 10 / 25\n",
      "----------\n",
      " Loss: 0.287307 - Accuracy 0.930556\n",
      " Loss: 0.269861 - Accuracy 0.934606\n",
      "Epoch 11 / 25\n",
      "----------\n",
      " Loss: 0.288164 - Accuracy 0.922454\n",
      " Loss: 0.249676 - Accuracy 0.943287\n",
      "Epoch 12 / 25\n",
      "----------\n",
      " Loss: 0.243483 - Accuracy 0.942130\n",
      " Loss: 0.220432 - Accuracy 0.950231\n",
      "Epoch 13 / 25\n",
      "----------\n",
      " Loss: 0.221477 - Accuracy 0.952546\n",
      " Loss: 0.235740 - Accuracy 0.942708\n",
      "Epoch 14 / 25\n",
      "----------\n",
      " Loss: 0.213458 - Accuracy 0.949074\n",
      " Loss: 0.213695 - Accuracy 0.943866\n",
      "Epoch 15 / 25\n",
      "----------\n",
      " Loss: 0.194028 - Accuracy 0.953704\n",
      " Loss: 0.183513 - Accuracy 0.957755\n",
      "Epoch 16 / 25\n",
      "----------\n",
      " Loss: 0.177410 - Accuracy 0.958333\n",
      " Loss: 0.226413 - Accuracy 0.935185\n",
      "Epoch 17 / 25\n",
      "----------\n",
      " Loss: 0.161484 - Accuracy 0.966435\n",
      " Loss: 0.184685 - Accuracy 0.956019\n",
      "Epoch 18 / 25\n",
      "----------\n",
      " Loss: 0.157986 - Accuracy 0.966435\n",
      " Loss: 0.156496 - Accuracy 0.963542\n",
      "Epoch 19 / 25\n",
      "----------\n",
      " Loss: 0.142827 - Accuracy 0.967593\n",
      " Loss: 0.163123 - Accuracy 0.960648\n",
      "Epoch 20 / 25\n",
      "----------\n",
      " Loss: 0.139389 - Accuracy 0.968750\n",
      " Loss: 0.125201 - Accuracy 0.976273\n",
      "Epoch 21 / 25\n",
      "----------\n",
      " Loss: 0.120425 - Accuracy 0.983796\n",
      " Loss: 0.117661 - Accuracy 0.980324\n",
      "Epoch 22 / 25\n",
      "----------\n",
      " Loss: 0.122576 - Accuracy 0.973380\n",
      " Loss: 0.109582 - Accuracy 0.979745\n",
      "Epoch 23 / 25\n",
      "----------\n",
      " Loss: 0.114956 - Accuracy 0.976852\n",
      " Loss: 0.116181 - Accuracy 0.977431\n",
      "Epoch 24 / 25\n",
      "----------\n",
      " Loss: 0.123267 - Accuracy 0.974537\n",
      " Loss: 0.120222 - Accuracy 0.973380\n",
      "Epoch 25 / 25\n",
      "----------\n",
      " Loss: 0.103566 - Accuracy 0.980324\n",
      " Loss: 0.095163 - Accuracy 0.984954\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(\"Epoch {} / {}\".format(epoch, num_epochs))\n",
    "    print(\"-\"*10)\n",
    "\n",
    "    running_loss = RunningMetric()\n",
    "    running_ac  = RunningMetric()\n",
    "    running_loss_v = RunningMetric()\n",
    "    running_ac_v  = RunningMetric()\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == \"train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            outputs1 = outputs.to('cpu')\n",
    "            _, preds = torch.max(outputs1, 1)\n",
    "            # preds = np.max(outputs1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            batch_size = inputs.size()[0]\n",
    "            running_loss.update(batch_size*loss.item(),\n",
    "                                batch_size)\n",
    "            running_ac.update(torch.sum(preds == targets.to('cpu')),\n",
    "                                batch_size)\n",
    "            print(\"\\r {} Loss: {:4f} - Accuracy {:4f}\".format(phase, running_loss(), running_ac()), end=\"\")\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c275c223988153440c22406204257a7f026fcd5c27fca1de1bf9fba5203f4143"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
